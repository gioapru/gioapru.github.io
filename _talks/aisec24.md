---
title: 'When Adversarial Perturbations meet Concept Drift: an Exploratory Analysis on ML-NIDS'
collection: talks
type: "Workshop"
excerpt: 'What happens when two popular phenomena in ML security join forces?'
badge: <span class='badge badge-danger'>Workshop</span>
permalink: /talks/aisec24
venue: "ACM Workshop on Artificial Intelligence Security (AISec)"
date: 2024-10-18
location: "Salt Lake City, Utah, USA"
---
{% include base_path %}

This is not a proper "talk", since we only presented our work as a poster (which was made in just 4 hours the night before the workshop). However, many people came to our poster: perhaps surprisingly, none of these knew about the problem of "concept drift" -- and, hence I had to explain it in a very simple way to (clearly) non-ML-savvy people. Hopefully, they found my explanations to be satisfactory!

Nonetheless, I liked doing so. I think that poster presentations are, from a certain perspective, _more_ interesting than regular presentations in which the audience cannot effectively interact with the speaker. 



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="{{ base_path }}/files/talks/aisec24_poster.pdf" target="_blank" rel="noopener">Poster</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://aisec.cc/" target="_blank" rel="noopener">Venue</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="{{base_path}}/publications/aisec24" rel="noopener">Paper</a>