---
title: "Addressing Adversarial Attacks Against Security Systems Based on Machine Learning"
collection: publications
permalink: /publications/cycon19
excerpt: 'It's not just a review! There's also an original defense against Poisoning!'
date: 2019-05-28
venue: 'International Conference on Cyber Conflict'
paperurl: ''
citation: 'Apruzzese, G., Marchetti, M., Colajanni, M., Zoccoli, G. G., & Guido, A. (2017, October). "Identifying malicious hosts involved in periodic communications". In <i> 2017 IEEE 16th International Symposium on Network Computing and Applications (NCA)</i> (pp. 1-8). IEEE.'
---
<b>Abstract.</b> Machine-learning solutions are successfully adopted in multiple contexts but the application of these techniques to the cyber security domain is complex and still immature. Among the many open issues that affect security systems based on machine learning, we concentrate on adversarial attacks that aim to affect the detection and prediction capabilities of machine-learning models. We consider realistic types of poisoning and evasion attacks targeting security solutions devoted to malware, spam and network intrusion detection. We explore the possible damages that an attacker can cause to a cyber detector and present some existing and original defensive techniques in the context of intrusion detection systems. This paper contains several performance evaluations that are based on extensive experiments using large traffic datasets. The results highlight that modern adversarial attacks are highly effective against machine-learning classifiers for cyber detection, and that existing solutions require improvements in several directions. The paper paves the way for more robust machine-learning-based techniques that can be integrated into cyber security platforms.

[[Paper PDF](https://gioapru.github.io/files/papers/cycon19/cycon19.pdf)], [[Bibtex](https://gioapru.github.io/files/papers/cycon19/cycon19.bib)]