---
title: "SoK: Pragmatic Assessment of Machine Learning for Network Intrusion Detection"
collection: publications
permalink: /publications/eurosp23
excerpt: "Changing the evaluation methodology of research papers on ML applications for NIDS."
date: 2023-04-04
code: '[EuroSP23]'
venue: 'IEEE European Symposium on Security and Privacy'
badge: <span class='badge badge-primary'>Conference</span>
type: Conference
authors: '<u>Apruzzese, G.</u>, Laskov, P., & Schneider, J.'
citation: 'Apruzzese, G., Laskov,. P, & Schneider, J. (2023, Jul). "SoK: Pragmatic Assessment of Machine Learning for Network Intrusion Detection." In <i>IEEE European Symposium on Security and Privacy (EuroS&P) </i>.'
---
{% include base_path %}
<b>Abstract.</b> Machine Learning (ML) has become a valuable asset to solve many real-world tasks. For Network Intrusion Detection (NID), however, scientific advances are still seen with skepticism by practitioners.
This disconnection is due to the intrinsically somewhat limited scope of research papers, many of which primarily aim to demonstrate new methods "outperforming" prior work---oftentimes overlooking the practical implications for deploying the proposed solutions in real systems.
Therefore, the value of ML for NID depends on a plethora of factors, such as hardware, that are often neglected in scientific literature.

This paper aims to reduce the practitioners' skepticism towards ML for NID by _changing_ the evaluation methodology adopted in research. After elucidating which _factors_ influence the operational deployment of ML in NID, we propose the notion of _pragmatic assessment_, which enable practitioners to gauge the real value of an ML method for NID. Then, we show that the state-of-research hardly allows one to estimate the value of ML for NID. As a constructive step forward, we carry out a pragmatic assessment. We re-assess existing ML methods for NID, focusing on the classification of malicious network traffic, and consider hundreds of configuration settings, diverse adversarial scenarios, and four hardware platforms. Our large and reproducible evaluations enable estimating the quality of ML for NID. We also validate our claims through a user-study with security practitioners.


<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="{{ base_path }}/files/papers/eurosp23/eurosp23.pdf" target="_blank" rel="noopener">Paper PDF</a> 
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="{{ base_path }}/files/papers/eurosp23/eurosp23_cite.html" target="_blank" rel="noopener">Cite</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://ieeexplore.ieee.org/document/" target="_blank" rel="noopener">IEEE Xplore</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://github.com/hihey54/pragmaticAssessment" target="_blank" rel="noopener">Artifact (Code)</a>
